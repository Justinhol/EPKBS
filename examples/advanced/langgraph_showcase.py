#!/usr/bin/env python3
"""
LangGraphåŠŸèƒ½å±•ç¤º
æ¼”ç¤ºLangGraphåœ¨EPKBSä¸­çš„å¼ºå¤§åŠŸèƒ½
"""
import asyncio
import json
import tempfile
from pathlib import Path

from src.agent.core import AgentCore
from src.rag.core import RAGCore
from src.utils.logger import get_logger

logger = get_logger("langgraph_showcase")


async def showcase_1_intelligent_document_processing():
    """å±•ç¤º1: æ™ºèƒ½æ–‡æ¡£å¤„ç†å·¥ä½œæµ"""
    logger.info("=== å±•ç¤º1: æ™ºèƒ½æ–‡æ¡£å¤„ç†å·¥ä½œæµ ===")
    
    # åˆ›å»ºå¤æ‚æµ‹è¯•æ–‡æ¡£
    complex_doc_content = """
# äººå·¥æ™ºèƒ½æŠ€æœ¯æŠ¥å‘Š

## æ‰§è¡Œæ‘˜è¦
æœ¬æŠ¥å‘Šåˆ†æäº†å½“å‰äººå·¥æ™ºèƒ½æŠ€æœ¯çš„å‘å±•çŠ¶å†µå’Œæœªæ¥è¶‹åŠ¿ã€‚

## æŠ€æœ¯åˆ†ç±»å¯¹æ¯”

### æœºå™¨å­¦ä¹ æŠ€æœ¯å¯¹æ¯”è¡¨
| æŠ€æœ¯ç±»å‹ | ä¼˜åŠ¿ | åŠ£åŠ¿ | é€‚ç”¨åœºæ™¯ | æˆç†Ÿåº¦ |
|----------|------|------|----------|--------|
| ç›‘ç£å­¦ä¹  | å‡†ç¡®ç‡é«˜ | éœ€è¦æ ‡æ³¨æ•°æ® | åˆ†ç±»ã€å›å½’ | é«˜ |
| æ— ç›‘ç£å­¦ä¹  | æ— éœ€æ ‡æ³¨ | è§£é‡Šæ€§å·® | èšç±»ã€é™ç»´ | ä¸­ |
| å¼ºåŒ–å­¦ä¹  | è‡ªä¸»å†³ç­– | è®­ç»ƒå¤æ‚ | æ¸¸æˆã€æ§åˆ¶ | ä¸­ |

### æ·±åº¦å­¦ä¹ æ¶æ„å¯¹æ¯”
| æ¶æ„ | å‚æ•°é‡ | è®­ç»ƒæ—¶é—´ | æ¨ç†é€Ÿåº¦ | åº”ç”¨é¢†åŸŸ |
|------|--------|----------|----------|----------|
| CNN | 1M-100M | å°æ—¶çº§ | æ¯«ç§’çº§ | å›¾åƒå¤„ç† |
| RNN | 10M-1B | å¤©çº§ | ç§’çº§ | åºåˆ—å»ºæ¨¡ |
| Transformer | 100M-100B | å‘¨çº§ | ç§’çº§ | è‡ªç„¶è¯­è¨€ |

## å¸‚åœºæ•°æ®åˆ†æ

### æŠ•èµ„è¶‹åŠ¿å›¾
[è¿™é‡Œåº”è¯¥æœ‰ä¸€ä¸ªæŠ•èµ„è¶‹åŠ¿å›¾è¡¨]

### æŠ€æœ¯é‡‡ç”¨ç‡
- æœºå™¨å­¦ä¹ : 85%
- æ·±åº¦å­¦ä¹ : 65%
- è‡ªç„¶è¯­è¨€å¤„ç†: 45%
- è®¡ç®—æœºè§†è§‰: 55%

## æ•°å­¦æ¨¡å‹

### æŸå¤±å‡½æ•°
äº¤å‰ç†µæŸå¤±: L = -âˆ‘(y_i * log(Å·_i))

### ä¼˜åŒ–ç®—æ³•
æ¢¯åº¦ä¸‹é™: Î¸ = Î¸ - Î±âˆ‡J(Î¸)

## ç»“è®º
äººå·¥æ™ºèƒ½æŠ€æœ¯æ­£åœ¨å¿«é€Ÿå‘å±•ï¼Œé¢„è®¡æœªæ¥5å¹´å°†æœ‰é‡å¤§çªç ´ã€‚
"""
    
    # åˆ›å»ºä¸´æ—¶æ–‡æ¡£
    with tempfile.NamedTemporaryFile(mode='w', suffix='.md', delete=False) as f:
        f.write(complex_doc_content)
        doc_path = f.name
    
    try:
        # åˆ›å»ºAgent
        agent = AgentCore(enable_mcp=True)
        await agent.initialize()
        
        logger.info(f"å¼€å§‹å¤„ç†å¤æ‚æ–‡æ¡£: {doc_path}")
        
        # ä½¿ç”¨LangGraphå·¥ä½œæµå¤„ç†æ–‡æ¡£
        result = await agent.parse_document_with_langgraph(doc_path)
        
        if result["success"]:
            logger.info("âœ… æ–‡æ¡£å¤„ç†æˆåŠŸ")
            
            # æ˜¾ç¤ºå¤„ç†æ‘˜è¦
            summary = result.get("result", {}).get("processing_summary", {})
            logger.info(f"å¤„ç†æ‘˜è¦:")
            logger.info(f"  - ä½¿ç”¨å·¥å…·: {summary.get('tools_list', [])}")
            logger.info(f"  - è´¨é‡åˆ†æ•°: {summary.get('quality_score', 0):.2f}")
            logger.info(f"  - å†…å®¹é•¿åº¦: {summary.get('content_length', 0)}")
            logger.info(f"  - åŒ…å«è¡¨æ ¼: {summary.get('has_tables', False)}")
            
            # æ˜¾ç¤ºå…ƒæ•°æ®
            metadata = result.get("result", {}).get("metadata", {})
            logger.info(f"å…ƒæ•°æ®:")
            logger.info(f"  - æ–‡ä»¶ç±»å‹: {metadata.get('file_info', {}).get('type')}")
            logger.info(f"  - å¤„ç†ç­–ç•¥: {metadata.get('processing_info', {}).get('strategy')}")
            logger.info(f"  - è¡¨æ ¼æ•°é‡: {metadata.get('content_info', {}).get('table_count', 0)}")
            
        else:
            logger.error(f"âŒ æ–‡æ¡£å¤„ç†å¤±è´¥: {result.get('error')}")
    
    finally:
        # æ¸…ç†
        Path(doc_path).unlink()
        if 'agent' in locals():
            if agent.mcp_server_manager:
                await agent.mcp_server_manager.stop_all_servers()


async def showcase_2_adaptive_agent_reasoning():
    """å±•ç¤º2: è‡ªé€‚åº”Agentæ¨ç†"""
    logger.info("=== å±•ç¤º2: è‡ªé€‚åº”Agentæ¨ç† ===")
    
    # åˆ›å»ºå¸¦RAGçš„Agent
    agent = await AgentCore.create_rag_agent(
        collection_name="showcase_knowledge",
        enable_mcp=True
    )
    
    try:
        # æµ‹è¯•ä¸åŒå¤æ‚åº¦çš„é—®é¢˜
        test_queries = [
            {
                "query": "ä½ å¥½",
                "expected_complexity": "simple",
                "description": "ç®€å•é—®å€™"
            },
            {
                "query": "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ",
                "expected_complexity": "medium", 
                "description": "æ¦‚å¿µè§£é‡Š"
            },
            {
                "query": "è¯·æ¯”è¾ƒç›‘ç£å­¦ä¹ ã€æ— ç›‘ç£å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ çš„ä¼˜ç¼ºç‚¹ï¼Œå¹¶ç»™å‡ºå…·ä½“çš„åº”ç”¨åœºæ™¯å’Œç®—æ³•ç¤ºä¾‹",
                "expected_complexity": "complex",
                "description": "å¤æ‚åˆ†æ"
            }
        ]
        
        for i, test_case in enumerate(test_queries, 1):
            logger.info(f"\n--- æµ‹è¯• {i}: {test_case['description']} ---")
            logger.info(f"é—®é¢˜: {test_case['query']}")
            
            # ä½¿ç”¨LangGraph Agentå¤„ç†
            result = await agent.chat_with_langgraph(
                test_case["query"], 
                use_rag=True
            )
            
            if result["success"]:
                logger.info(f"âœ… å›ç­”æˆåŠŸ")
                logger.info(f"æ¨¡å¼: {result.get('mode')}")
                logger.info(f"æ‰§è¡Œæ—¶é—´: {result.get('execution_time', 0):.2f}s")
                
                # æ˜¾ç¤ºæ¨ç†æ­¥éª¤
                langgraph_result = result.get("langgraph_result", {})
                reasoning_steps = langgraph_result.get("reasoning_steps", [])
                if reasoning_steps:
                    logger.info(f"æ¨ç†æ­¥éª¤: {len(reasoning_steps)} æ­¥")
                    for j, step in enumerate(reasoning_steps[:3], 1):  # åªæ˜¾ç¤ºå‰3æ­¥
                        logger.info(f"  æ­¥éª¤ {j}: {step.get('tool', 'N/A')}")
                
                # æ˜¾ç¤ºå›ç­”é¢„è§ˆ
                response = result.get("response", "")
                preview = response[:100] + "..." if len(response) > 100 else response
                logger.info(f"å›ç­”é¢„è§ˆ: {preview}")
                
            else:
                logger.error(f"âŒ å›ç­”å¤±è´¥: {result.get('error')}")
    
    finally:
        # æ¸…ç†
        if agent.mcp_server_manager:
            await agent.mcp_server_manager.stop_all_servers()


async def showcase_3_workflow_composition():
    """å±•ç¤º3: å·¥ä½œæµç»„åˆå’Œç¼–æ’"""
    logger.info("=== å±•ç¤º3: å·¥ä½œæµç»„åˆå’Œç¼–æ’ ===")
    
    agent = AgentCore(enable_mcp=True)
    await agent.initialize()
    
    try:
        # åˆ›å»ºå¤šä¸ªæµ‹è¯•æ–‡æ¡£
        documents = []
        doc_contents = [
            "# æŠ€æœ¯æ–‡æ¡£1\n\nè¿™æ˜¯å…³äºæœºå™¨å­¦ä¹ çš„æ–‡æ¡£ã€‚",
            "# æŠ€æœ¯æ–‡æ¡£2\n\nè¿™æ˜¯å…³äºæ·±åº¦å­¦ä¹ çš„æ–‡æ¡£ã€‚",
            "# æŠ€æœ¯æ–‡æ¡£3\n\nè¿™æ˜¯å…³äºè‡ªç„¶è¯­è¨€å¤„ç†çš„æ–‡æ¡£ã€‚"
        ]
        
        for i, content in enumerate(doc_contents):
            with tempfile.NamedTemporaryFile(mode='w', suffix='.md', delete=False) as f:
                f.write(content)
                documents.append(f.name)
        
        logger.info(f"åˆ›å»ºäº† {len(documents)} ä¸ªæµ‹è¯•æ–‡æ¡£")
        
        # 1. æ‰¹é‡æ–‡æ¡£å¤„ç†
        logger.info("1. æ‰§è¡Œæ‰¹é‡æ–‡æ¡£å¤„ç†...")
        batch_result = await agent.batch_process_documents_with_langgraph(documents)
        
        if batch_result["success"]:
            logger.info(f"âœ… æ‰¹é‡å¤„ç†æˆåŠŸ")
            logger.info(f"  - æ€»æ–‡ä»¶: {batch_result['total_files']}")
            logger.info(f"  - æˆåŠŸ: {batch_result['successful']}")
            logger.info(f"  - å¤±è´¥: {batch_result['failed']}")
            logger.info(f"  - æˆåŠŸç‡: {batch_result['success_rate']:.2%}")
            logger.info(f"  - ååé‡: {batch_result['throughput']:.2f} æ–‡ä»¶/ç§’")
        
        # 2. åŸºäºå¤„ç†ç»“æœçš„æ™ºèƒ½é—®ç­”
        logger.info("\n2. åŸºäºå¤„ç†ç»“æœçš„æ™ºèƒ½é—®ç­”...")
        qa_result = await agent.chat_with_langgraph(
            "æ ¹æ®åˆšæ‰å¤„ç†çš„æ–‡æ¡£ï¼Œæ€»ç»“ä¸€ä¸‹AIæŠ€æœ¯çš„ä¸»è¦åˆ†ç±»", 
            use_rag=True
        )
        
        if qa_result["success"]:
            logger.info(f"âœ… æ™ºèƒ½é—®ç­”æˆåŠŸ")
            logger.info(f"å›ç­”: {qa_result['response'][:200]}...")
        
        # 3. å·¥ä½œæµå¯è§†åŒ–
        logger.info("\n3. ç”Ÿæˆå·¥ä½œæµå¯è§†åŒ–...")
        for workflow_type in ["document", "agent", "rag"]:
            viz = await agent.get_workflow_visualization(workflow_type)
            if viz:
                logger.info(f"âœ… {workflow_type} å·¥ä½œæµå¯è§†åŒ–ç”ŸæˆæˆåŠŸ")
                # ä¿å­˜åˆ°æ–‡ä»¶
                viz_file = f"workflow_{workflow_type}.mermaid"
                with open(viz_file, 'w') as f:
                    f.write(viz)
                logger.info(f"å¯è§†åŒ–å·²ä¿å­˜åˆ°: {viz_file}")
        
        # 4. æ€§èƒ½ç»Ÿè®¡
        logger.info("\n4. æ€§èƒ½ç»Ÿè®¡åˆ†æ...")
        stats = agent.get_agent_statistics()
        logger.info(f"Agentç»Ÿè®¡: {json.dumps(stats, indent=2, ensure_ascii=False)}")
        
    finally:
        # æ¸…ç†æµ‹è¯•æ–‡æ¡£
        for doc_path in documents:
            Path(doc_path).unlink()
        
        # åœæ­¢æœåŠ¡å™¨
        if agent.mcp_server_manager:
            await agent.mcp_server_manager.stop_all_servers()


async def showcase_4_real_world_scenario():
    """å±•ç¤º4: çœŸå®ä¸–ç•Œåœºæ™¯æ¨¡æ‹Ÿ"""
    logger.info("=== å±•ç¤º4: çœŸå®ä¸–ç•Œåœºæ™¯æ¨¡æ‹Ÿ ===")
    
    # æ¨¡æ‹Ÿä¼ä¸šæ–‡æ¡£å¤„ç†åœºæ™¯
    scenario_description = """
åœºæ™¯: ä¼ä¸šéœ€è¦å¤„ç†ä¸€æ‰¹æŠ€æœ¯æ–‡æ¡£ï¼ŒåŒ…æ‹¬ï¼š
1. äº§å“è§„æ ¼ä¹¦ï¼ˆåŒ…å«å¤§é‡è¡¨æ ¼ï¼‰
2. æŠ€æœ¯æŠ¥å‘Šï¼ˆåŒ…å«å›¾è¡¨å’Œå…¬å¼ï¼‰
3. ç”¨æˆ·æ‰‹å†Œï¼ˆåŒ…å«å›¾ç‰‡è¯´æ˜ï¼‰

è¦æ±‚: 
- è‡ªåŠ¨è§£ææ‰€æœ‰æ–‡æ¡£
- æå–å…³é”®ä¿¡æ¯
- ç”Ÿæˆç»“æ„åŒ–æ‘˜è¦
- æ”¯æŒæ™ºèƒ½é—®ç­”
"""
    
    logger.info(scenario_description)
    
    agent = AgentCore(enable_mcp=True)
    await agent.initialize()
    
    try:
        # æ¨¡æ‹Ÿä¼ä¸šæ–‡æ¡£
        enterprise_docs = [
            {
                "name": "äº§å“è§„æ ¼ä¹¦.md",
                "content": """
# äº§å“è§„æ ¼ä¹¦

## æŠ€æœ¯å‚æ•°
| å‚æ•° | æ•°å€¼ | å•ä½ | å¤‡æ³¨ |
|------|------|------|------|
| CPU | 8æ ¸ | æ ¸å¿ƒ | é«˜æ€§èƒ½å¤„ç†å™¨ |
| å†…å­˜ | 32GB | GB | DDR4 |
| å­˜å‚¨ | 1TB | TB | SSD |

## æ€§èƒ½æŒ‡æ ‡
| æŒ‡æ ‡ | æ•°å€¼ | æ ‡å‡† |
|------|------|------|
| å“åº”æ—¶é—´ | <100ms | ä¼˜ç§€ |
| ååé‡ | 1000 QPS | è‰¯å¥½ |
| å¯ç”¨æ€§ | 99.9% | ä¼ä¸šçº§ |
"""
            },
            {
                "name": "æŠ€æœ¯æŠ¥å‘Š.md", 
                "content": """
# AIç³»ç»ŸæŠ€æœ¯æŠ¥å‘Š

## ç®—æ³•æ€§èƒ½åˆ†æ

### å‡†ç¡®ç‡å¯¹æ¯”
| æ¨¡å‹ | å‡†ç¡®ç‡ | F1åˆ†æ•° | è®­ç»ƒæ—¶é—´ |
|------|--------|--------|----------|
| BERT | 92.5% | 0.91 | 4å°æ—¶ |
| GPT-3 | 94.2% | 0.93 | 12å°æ—¶ |
| T5 | 93.1% | 0.92 | 8å°æ—¶ |

## æ•°å­¦æ¨¡å‹

### æ³¨æ„åŠ›æœºåˆ¶
Attention(Q,K,V) = softmax(QK^T/âˆšd_k)V

### æŸå¤±å‡½æ•°
L = -âˆ‘(y_i * log(Å·_i))

## ç»“è®º
åŸºäºå®éªŒç»“æœï¼Œæ¨èä½¿ç”¨GPT-3æ¨¡å‹ã€‚
"""
            }
        ]
        
        # åˆ›å»ºä¸´æ—¶æ–‡æ¡£æ–‡ä»¶
        doc_paths = []
        for doc_info in enterprise_docs:
            with tempfile.NamedTemporaryFile(mode='w', suffix='.md', delete=False) as f:
                f.write(doc_info["content"])
                doc_paths.append(f.name)
        
        # 1. æ‰¹é‡æ™ºèƒ½å¤„ç†
        logger.info("1. æ‰¹é‡æ™ºèƒ½å¤„ç†ä¼ä¸šæ–‡æ¡£...")
        batch_result = await agent.batch_process_documents_with_langgraph(doc_paths)
        
        if batch_result["success"]:
            logger.info("âœ… æ‰¹é‡å¤„ç†å®Œæˆ")
            logger.info(f"å¤„ç†ç»“æœ:")
            logger.info(f"  - æˆåŠŸç‡: {batch_result['success_rate']:.2%}")
            logger.info(f"  - å¹³å‡å¤„ç†æ—¶é—´: {batch_result['execution_time']/len(doc_paths):.2f}s/æ–‡æ¡£")
            
            # æ˜¾ç¤ºæ¯ä¸ªæ–‡æ¡£çš„å¤„ç†ç»“æœ
            for result in batch_result["results"]:
                if result["success"]:
                    summary = result.get("processing_summary", {})
                    logger.info(f"  ğŸ“„ {Path(result['file_path']).name}:")
                    logger.info(f"    - è´¨é‡åˆ†æ•°: {summary.get('quality_score', 0):.2f}")
                    logger.info(f"    - åŒ…å«è¡¨æ ¼: {summary.get('has_tables', False)}")
                    logger.info(f"    - ä½¿ç”¨å·¥å…·: {len(summary.get('tools_list', []))}")
        
        # 2. æ™ºèƒ½é—®ç­”æµ‹è¯•
        logger.info("\n2. åŸºäºå¤„ç†ç»“æœçš„æ™ºèƒ½é—®ç­”...")
        
        questions = [
            "è¿™äº›æ–‡æ¡£ä¸­æåˆ°äº†å“ªäº›AIæŠ€æœ¯ï¼Ÿ",
            "äº§å“çš„æŠ€æœ¯å‚æ•°æ˜¯ä»€ä¹ˆï¼Ÿ",
            "ä¸åŒAIæ¨¡å‹çš„æ€§èƒ½å¯¹æ¯”å¦‚ä½•ï¼Ÿ",
            "æ–‡æ¡£ä¸­æåˆ°çš„æ•°å­¦å…¬å¼æœ‰å“ªäº›ï¼Ÿ"
        ]
        
        for question in questions:
            logger.info(f"\né—®é¢˜: {question}")
            
            answer_result = await agent.chat_with_langgraph(question, use_rag=True)
            
            if answer_result["success"]:
                logger.info(f"âœ… å›ç­”: {answer_result['response'][:150]}...")
                logger.info(f"æ¨¡å¼: {answer_result.get('mode')}")
            else:
                logger.error(f"âŒ å›ç­”å¤±è´¥: {answer_result.get('error')}")
        
        # 3. å·¥ä½œæµæ€§èƒ½åˆ†æ
        logger.info("\n3. å·¥ä½œæµæ€§èƒ½åˆ†æ...")
        stats = agent.get_agent_statistics()
        
        logger.info("æ€§èƒ½ç»Ÿè®¡:")
        logger.info(f"  - LangGraph Agent: {'å¯ç”¨' if stats['langgraph_agent']['enabled'] else 'ç¦ç”¨'}")
        logger.info(f"  - å¯ç”¨å·¥å…·æ•°: {stats['langgraph_agent']['tools']}")
        logger.info(f"  - å·¥ä½œæµæ•°: {stats['langgraph_agent']['workflows']}")
        logger.info(f"  - å¯¹è¯å†å²: {stats['conversation_history']} æ¡")
        
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        for doc_path in doc_paths:
            Path(doc_path).unlink()
        
        # åœæ­¢æœåŠ¡å™¨
        if agent.mcp_server_manager:
            await agent.mcp_server_manager.stop_all_servers()


async def showcase_5_workflow_visualization():
    """å±•ç¤º5: å·¥ä½œæµå¯è§†åŒ–"""
    logger.info("=== å±•ç¤º5: å·¥ä½œæµå¯è§†åŒ– ===")
    
    agent = AgentCore(enable_mcp=True)
    await agent.initialize()
    
    try:
        workflow_types = [
            ("document", "æ–‡æ¡£å¤„ç†å·¥ä½œæµ"),
            ("agent", "Agentæ¨ç†å·¥ä½œæµ"),
            ("rag", "RAGæ£€ç´¢å·¥ä½œæµ")
        ]
        
        for workflow_type, description in workflow_types:
            logger.info(f"\nç”Ÿæˆ {description} å¯è§†åŒ–...")
            
            mermaid_code = await agent.get_workflow_visualization(workflow_type)
            
            if mermaid_code:
                logger.info(f"âœ… {description} å¯è§†åŒ–ç”ŸæˆæˆåŠŸ")
                
                # ä¿å­˜Mermaidä»£ç 
                output_file = f"docs/workflows/{workflow_type}_workflow.mermaid"
                Path("docs/workflows").mkdir(exist_ok=True)
                
                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write(mermaid_code)
                
                logger.info(f"å¯è§†åŒ–å·²ä¿å­˜åˆ°: {output_file}")
                
                # æ˜¾ç¤ºéƒ¨åˆ†ä»£ç 
                preview = mermaid_code[:200] + "..." if len(mermaid_code) > 200 else mermaid_code
                logger.info(f"é¢„è§ˆ:\n{preview}")
                
            else:
                logger.warning(f"âŒ {description} å¯è§†åŒ–ç”Ÿæˆå¤±è´¥")
    
    finally:
        # åœæ­¢æœåŠ¡å™¨
        if agent.mcp_server_manager:
            await agent.mcp_server_manager.stop_all_servers()


async def main():
    """ä¸»å‡½æ•° - è¿è¡Œæ‰€æœ‰å±•ç¤º"""
    logger.info("ğŸš€ å¼€å§‹LangGraphåŠŸèƒ½å±•ç¤º")
    
    showcases = [
        ("æ™ºèƒ½æ–‡æ¡£å¤„ç†å·¥ä½œæµ", showcase_1_intelligent_document_processing),
        ("è‡ªé€‚åº”Agentæ¨ç†", showcase_2_adaptive_agent_reasoning),
        ("å·¥ä½œæµå¯è§†åŒ–", showcase_5_workflow_visualization)
    ]
    
    for name, showcase_func in showcases:
        try:
            logger.info(f"\n{'='*60}")
            logger.info(f"ğŸ¯ {name}")
            logger.info(f"{'='*60}")
            
            await showcase_func()
            
            logger.info(f"âœ… å±•ç¤º '{name}' å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ å±•ç¤º '{name}' å¤±è´¥: {e}")
        
        # ç­‰å¾…ä¸€ä¸‹å†è¿è¡Œä¸‹ä¸€ä¸ªå±•ç¤º
        await asyncio.sleep(2)
    
    logger.info("\nğŸ‰ æ‰€æœ‰LangGraphåŠŸèƒ½å±•ç¤ºå®Œæˆï¼")
    logger.info("\nğŸ“Š æ€»ç»“:")
    logger.info("âœ… LangGraphæä¾›äº†å¼ºå¤§çš„çŠ¶æ€ç®¡ç†å’Œå·¥ä½œæµç¼–æ’èƒ½åŠ›")
    logger.info("âœ… æ™ºèƒ½Agentå¯ä»¥æ ¹æ®ä»»åŠ¡å¤æ‚åº¦è‡ªé€‚åº”é€‰æ‹©ç­–ç•¥")
    logger.info("âœ… å·¥ä½œæµå¯è§†åŒ–å¸®åŠ©ç†è§£å’Œè°ƒè¯•å¤æ‚æµç¨‹")
    logger.info("âœ… æ‰¹é‡å¤„ç†å’Œå¹¶è¡Œæ‰§è¡Œå¤§å¤§æå‡äº†æ•ˆç‡")


if __name__ == "__main__":
    asyncio.run(main())
