#!/usr/bin/env python3
"""
Qwen3æ¨¡å‹å‡çº§è„šæœ¬
éªŒè¯å’Œå‡çº§åˆ°Qwen3ç³»åˆ—æ¨¡å‹
"""
import asyncio
import sys
import os
from pathlib import Path
from typing import Dict, Any, List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.utils.logger import get_logger

logger = get_logger("upgrade.qwen3")

class Qwen3Upgrader:
    """Qwen3å‡çº§å™¨"""
    
    def __init__(self):
        self.qwen3_models = {
            "LLM": "Qwen/Qwen3-8B",
            "Embedding": "Qwen/Qwen3-Embedding-8B", 
            "Reranker": "Qwen/Qwen3-Reranker-8B"
        }
        
        self.old_models = {
            "LLM": "Qwen/Qwen2.5-8B-Instruct",
            "Embedding": "Qwen/Qwen2.5-Embedding-8B",
            "Reranker": "Qwen/Qwen2.5-Reranker-4B"
        }
        
        logger.info("Qwen3å‡çº§å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def check_model_availability(self, model_name: str) -> bool:
        """æ£€æŸ¥æ¨¡å‹åœ¨Hugging Faceä¸Šçš„å¯ç”¨æ€§"""
        try:
            from huggingface_hub import model_info
            info = model_info(model_name)
            return True
        except Exception as e:
            logger.error(f"æ¨¡å‹ {model_name} ä¸å¯ç”¨: {e}")
            return False
    
    def check_all_models(self) -> Dict[str, bool]:
        """æ£€æŸ¥æ‰€æœ‰Qwen3æ¨¡å‹çš„å¯ç”¨æ€§"""
        logger.info("æ£€æŸ¥Qwen3æ¨¡å‹å¯ç”¨æ€§...")
        
        results = {}
        for model_type, model_name in self.qwen3_models.items():
            logger.info(f"æ£€æŸ¥ {model_type} æ¨¡å‹: {model_name}")
            results[model_type] = self.check_model_availability(model_name)
        
        return results
    
    def test_model_loading(self, model_name: str, model_type: str) -> bool:
        """æµ‹è¯•æ¨¡å‹åŠ è½½"""
        try:
            logger.info(f"æµ‹è¯•åŠ è½½ {model_type} æ¨¡å‹: {model_name}")
            
            if model_type == "LLM":
                from transformers import AutoTokenizer, AutoModelForCausalLM
                tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
                # åªåŠ è½½tokenizerï¼Œä¸åŠ è½½å®Œæ•´æ¨¡å‹ä»¥èŠ‚çœæ—¶é—´å’Œå†…å­˜
                logger.info(f"âœ… {model_type} tokenizer åŠ è½½æˆåŠŸ")
                return True
                
            elif model_type == "Embedding":
                from sentence_transformers import SentenceTransformer
                # åªæ£€æŸ¥æ¨¡å‹é…ç½®ï¼Œä¸å®é™…åŠ è½½
                from transformers import AutoConfig
                config = AutoConfig.from_pretrained(model_name, trust_remote_code=True)
                logger.info(f"âœ… {model_type} é…ç½®åŠ è½½æˆåŠŸ")
                return True
                
            elif model_type == "Reranker":
                from transformers import AutoConfig
                config = AutoConfig.from_pretrained(model_name, trust_remote_code=True)
                logger.info(f"âœ… {model_type} é…ç½®åŠ è½½æˆåŠŸ")
                return True
                
        except Exception as e:
            logger.error(f"âŒ {model_type} æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False
    
    def backup_current_config(self):
        """å¤‡ä»½å½“å‰é…ç½®"""
        logger.info("å¤‡ä»½å½“å‰é…ç½®...")
        
        config_files = [".env", "config/settings.py"]
        
        for config_file in config_files:
            if os.path.exists(config_file):
                backup_file = f"{config_file}.backup"
                try:
                    import shutil
                    shutil.copy2(config_file, backup_file)
                    logger.info(f"âœ… å¤‡ä»½ {config_file} -> {backup_file}")
                except Exception as e:
                    logger.error(f"âŒ å¤‡ä»½ {config_file} å¤±è´¥: {e}")
    
    def update_env_file(self):
        """æ›´æ–°.envæ–‡ä»¶"""
        logger.info("æ›´æ–°.envæ–‡ä»¶...")
        
        env_file = ".env"
        if not os.path.exists(env_file):
            logger.warning(".envæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡æ›´æ–°")
            return
        
        try:
            with open(env_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æ›´æ–°æ¨¡å‹è·¯å¾„
            replacements = {
                "Qwen/Qwen2.5-8B-Instruct": "Qwen/Qwen3-8B",
                "Qwen/Qwen2.5-Embedding-8B": "Qwen/Qwen3-Embedding-8B", 
                "Qwen/Qwen2.5-Reranker-4B": "Qwen/Qwen3-Reranker-8B",
                "BAAI/bge-large-zh-v1.5": "Qwen/Qwen3-Embedding-8B",
                "BAAI/bge-reranker-large": "Qwen/Qwen3-Reranker-8B"
            }
            
            for old_model, new_model in replacements.items():
                if old_model in content:
                    content = content.replace(old_model, new_model)
                    logger.info(f"âœ… æ›´æ–°: {old_model} -> {new_model}")
            
            with open(env_file, 'w', encoding='utf-8') as f:
                f.write(content)
            
            logger.info("âœ… .envæ–‡ä»¶æ›´æ–°å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°.envæ–‡ä»¶å¤±è´¥: {e}")
    
    def verify_upgrade(self) -> bool:
        """éªŒè¯å‡çº§ç»“æœ"""
        logger.info("éªŒè¯å‡çº§ç»“æœ...")
        
        try:
            # é‡æ–°åŠ è½½é…ç½®
            from config.settings import settings
            
            current_models = {
                "LLM": settings.QWEN_MODEL_PATH,
                "Embedding": settings.EMBEDDING_MODEL_PATH,
                "Reranker": settings.RERANKER_MODEL_PATH
            }
            
            logger.info("å½“å‰æ¨¡å‹é…ç½®:")
            for model_type, model_name in current_models.items():
                logger.info(f"  {model_type}: {model_name}")
            
            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†Qwen3æ¨¡å‹
            qwen3_count = 0
            for model_type, model_name in current_models.items():
                if "Qwen3" in model_name or "Qwen/Qwen3" in model_name:
                    qwen3_count += 1
                    logger.info(f"âœ… {model_type} å·²å‡çº§åˆ°Qwen3")
                else:
                    logger.warning(f"âš ï¸ {model_type} æœªä½¿ç”¨Qwen3: {model_name}")
            
            success_rate = qwen3_count / len(current_models) * 100
            logger.info(f"Qwen3å‡çº§ç‡: {success_rate:.1f}%")
            
            return qwen3_count >= 2  # è‡³å°‘2ä¸ªæ¨¡å‹ä½¿ç”¨Qwen3
            
        except Exception as e:
            logger.error(f"éªŒè¯å‡çº§å¤±è´¥: {e}")
            return False
    
    def show_upgrade_benefits(self):
        """æ˜¾ç¤ºå‡çº§ä¼˜åŠ¿"""
        print("\n" + "="*60)
        print("ğŸš€ Qwen3ç³»åˆ—æ¨¡å‹ä¼˜åŠ¿")
        print("="*60)
        
        benefits = [
            "ğŸ§  æ›´å¼ºçš„æ¨ç†èƒ½åŠ› - æ”¯æŒæ€ç»´é“¾æ¨ç†æ¨¡å¼",
            "ğŸ¯ æ›´é«˜çš„å‡†ç¡®æ€§ - ä¸­æ–‡ç†è§£èƒ½åŠ›æå‡7-8%", 
            "ğŸ” æ›´å¥½çš„æ£€ç´¢æ•ˆæœ - åµŒå…¥æ¨¡å‹ç²¾åº¦æå‡6%",
            "âš¡ æ›´å¿«çš„æ¨ç†é€Ÿåº¦ - ä¼˜åŒ–çš„æ¨¡å‹æ¶æ„",
            "ğŸ”„ ç»Ÿä¸€çš„æ¨¡å‹å®¶æ— - æ›´å¥½çš„å…¼å®¹æ€§",
            "ğŸ“ˆ æŒç»­çš„æ›´æ–°æ”¯æŒ - é˜¿é‡Œå·´å·´æœ€æ–°æŠ€æœ¯"
        ]
        
        for benefit in benefits:
            print(f"  {benefit}")
        
        print("="*60)
    
    def show_migration_guide(self):
        """æ˜¾ç¤ºè¿ç§»æŒ‡å—"""
        print("\n" + "="*60)
        print("ğŸ“‹ Qwen3è¿ç§»æŒ‡å—")
        print("="*60)
        
        print("1. æ¨¡å‹å¯¹åº”å…³ç³»:")
        print("   Qwen2.5-8B-Instruct    -> Qwen3-8B")
        print("   Qwen2.5-Embedding-8B   -> Qwen3-Embedding-8B")
        print("   Qwen2.5-Reranker-4B    -> Qwen3-Reranker-8B")
        print("   BGE-large-zh-v1.5      -> Qwen3-Embedding-8B")
        print("   BGE-reranker-large     -> Qwen3-Reranker-8B")
        
        print("\n2. é…ç½®æ›´æ–°:")
        print("   QWEN_MODEL_PATH=Qwen/Qwen3-8B")
        print("   EMBEDDING_MODEL_PATH=Qwen/Qwen3-Embedding-8B")
        print("   RERANKER_MODEL_PATH=Qwen/Qwen3-Reranker-8B")
        
        print("\n3. æ³¨æ„äº‹é¡¹:")
        print("   - é¦–æ¬¡ä½¿ç”¨ä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹ï¼ˆçº¦15-20GBï¼‰")
        print("   - å»ºè®®ä½¿ç”¨16GB+å†…å­˜çš„æœºå™¨")
        print("   - æ”¯æŒCPUå’ŒGPUæ¨ç†")
        print("   - å…¼å®¹ç°æœ‰çš„APIæ¥å£")
        
        print("="*60)
    
    async def run_upgrade(self):
        """è¿è¡Œå‡çº§æµç¨‹"""
        logger.info("å¼€å§‹Qwen3å‡çº§æµç¨‹...")
        
        # 1. æ˜¾ç¤ºå‡çº§ä¼˜åŠ¿
        self.show_upgrade_benefits()
        
        # 2. æ£€æŸ¥æ¨¡å‹å¯ç”¨æ€§
        availability = self.check_all_models()
        
        available_count = sum(availability.values())
        total_count = len(availability)
        
        print(f"\nğŸ“Š æ¨¡å‹å¯ç”¨æ€§æ£€æŸ¥ç»“æœ: {available_count}/{total_count}")
        for model_type, available in availability.items():
            status = "âœ… å¯ç”¨" if available else "âŒ ä¸å¯ç”¨"
            print(f"  {model_type}: {status}")
        
        if available_count < total_count:
            logger.error("éƒ¨åˆ†Qwen3æ¨¡å‹ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•")
            return False
        
        # 3. æµ‹è¯•æ¨¡å‹åŠ è½½
        print("\nğŸ§ª æµ‹è¯•æ¨¡å‹åŠ è½½...")
        loading_results = {}
        for model_type, model_name in self.qwen3_models.items():
            loading_results[model_type] = self.test_model_loading(model_name, model_type)
        
        loading_success = sum(loading_results.values())
        print(f"æ¨¡å‹åŠ è½½æµ‹è¯•: {loading_success}/{len(loading_results)}")
        
        # 4. è¯¢é—®ç”¨æˆ·æ˜¯å¦ç»§ç»­
        print(f"\nâ“ æ˜¯å¦ç»§ç»­å‡çº§åˆ°Qwen3ç³»åˆ—æ¨¡å‹ï¼Ÿ")
        print("   - å°†å¤‡ä»½å½“å‰é…ç½®")
        print("   - æ›´æ–°æ¨¡å‹è·¯å¾„åˆ°Qwen3ç³»åˆ—")
        print("   - é¦–æ¬¡ä½¿ç”¨æ—¶ä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹")
        
        response = input("ç»§ç»­å‡çº§ï¼Ÿ(y/N): ").strip().lower()
        if response not in ['y', 'yes']:
            logger.info("ç”¨æˆ·å–æ¶ˆå‡çº§")
            return False
        
        # 5. æ‰§è¡Œå‡çº§
        logger.info("æ‰§è¡Œå‡çº§...")
        
        # å¤‡ä»½é…ç½®
        self.backup_current_config()
        
        # æ›´æ–°é…ç½®æ–‡ä»¶
        self.update_env_file()
        
        # 6. éªŒè¯å‡çº§
        if self.verify_upgrade():
            logger.info("âœ… Qwen3å‡çº§æˆåŠŸï¼")
            self.show_migration_guide()
            
            print("\nğŸ‰ å‡çº§å®Œæˆï¼")
            print("è¯·é‡å¯ç³»ç»Ÿä»¥ä½¿ç”¨æ–°çš„Qwen3æ¨¡å‹ã€‚")
            print("è¿è¡Œå‘½ä»¤: python scripts/start_services.py")
            
            return True
        else:
            logger.error("âŒ å‡çº§éªŒè¯å¤±è´¥")
            return False


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ ä¼ä¸šç§æœ‰çŸ¥è¯†åº“ç³»ç»Ÿ - Qwen3å‡çº§å·¥å…·")
    print("="*60)
    
    try:
        upgrader = Qwen3Upgrader()
        success = await upgrader.run_upgrade()
        
        if success:
            print("\nâœ… å‡çº§æˆåŠŸå®Œæˆï¼")
            sys.exit(0)
        else:
            print("\nâŒ å‡çº§å¤±è´¥æˆ–è¢«å–æ¶ˆ")
            sys.exit(1)
            
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­å‡çº§")
        sys.exit(1)
    except Exception as e:
        logger.error(f"å‡çº§è¿‡ç¨‹å‡ºé”™: {e}")
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
