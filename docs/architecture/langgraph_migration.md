# ğŸ”„ LangGraphå…¨é¢è¿ç§»æŒ‡å—

## ğŸ¯ è¿ç§»æ¦‚è¿°

EPKBSé¡¹ç›®å·²å…¨é¢è¿ç§»åˆ°LangGraphæ¡†æ¶ï¼Œå®ç°äº†æ›´å¼ºå¤§çš„çŠ¶æ€ç®¡ç†ã€å·¥ä½œæµç¼–æ’å’Œæ™ºèƒ½æ¨ç†èƒ½åŠ›ã€‚

## ğŸ—ï¸ æ¶æ„å¯¹æ¯”

### è¿ç§»å‰ (LangChain)
```
ç”¨æˆ·è¯·æ±‚ â†’ LLM â†’ å·¥å…·è°ƒç”¨ â†’ ç»“æœè¿”å›
```

### è¿ç§»å (LangGraph)
```
ç”¨æˆ·è¯·æ±‚ â†’ çŠ¶æ€å›¾ â†’ æ™ºèƒ½èŠ‚ç‚¹ â†’ æ¡ä»¶è·¯ç”± â†’ å¹¶è¡Œæ‰§è¡Œ â†’ çŠ¶æ€æ›´æ–° â†’ ç»“æœè¿”å›
```

## ğŸ”§ æ ¸å¿ƒæ”¹è¿›

### 1. çŠ¶æ€ç®¡ç†å‡çº§

#### **ä¹‹å‰ (LangChain)**
```python
# ç®€å•çš„é“¾å¼è°ƒç”¨ï¼ŒçŠ¶æ€ç®¡ç†æœ‰é™
chain = LLMChain(llm=llm, prompt=prompt)
result = chain.run(input_text)
```

#### **ç°åœ¨ (LangGraph)**
```python
# å¼ºå¤§çš„çŠ¶æ€ç®¡ç†å’Œå·¥ä½œæµæ§åˆ¶
from langgraph.graph import StateGraph
from .states import DocumentProcessingState

workflow = StateGraph(DocumentProcessingState)
workflow.add_node("parse", parse_node)
workflow.add_conditional_edges("parse", route_function, {...})
result = await workflow.ainvoke(initial_state)
```

### 2. å·¥ä½œæµç¼–æ’

#### **æ–‡æ¡£å¤„ç†å·¥ä½œæµ**
```mermaid
graph TD
    A[æ£€æµ‹æ–‡æ¡£æ ¼å¼] --> B[åŸºç¡€è§£æ]
    B --> C[è´¨é‡è¯„ä¼°]
    C --> D{éœ€è¦é«˜çº§å¤„ç†?}
    D -->|æ˜¯| E[é«˜çº§å¤„ç†]
    D -->|å¦| F[æ•´åˆç»“æœ]
    E --> F
    F --> G[å®Œæˆ]
```

#### **Agentæ¨ç†å·¥ä½œæµ**
```mermaid
graph TD
    A[æ€è€ƒ] --> B{æœ‰æ˜ç¡®è¡ŒåŠ¨?}
    B -->|æ˜¯| C[æ‰§è¡Œè¡ŒåŠ¨]
    B -->|å¦| D[æœ€ç»ˆç­”æ¡ˆ]
    C --> E[è§‚å¯Ÿç»“æœ]
    E --> F{ç»§ç»­æ¨ç†?}
    F -->|æ˜¯| A
    F -->|å¦| D
```

### 3. æ™ºèƒ½è·¯ç”±å†³ç­–

```python
def route_parsing_strategy(state: DocumentProcessingState) -> str:
    """æ™ºèƒ½è·¯ç”±ï¼šæ ¹æ®æ–‡æ¡£ç‰¹å¾é€‰æ‹©å¤„ç†ç­–ç•¥"""
    
    if state["quality_details"]["has_tables"]:
        return "table_extraction_flow"
    elif state["quality_details"]["has_images"]:
        return "image_analysis_flow"
    elif state["quality_details"]["has_formulas"]:
        return "formula_recognition_flow"
    else:
        return "standard_flow"
```

## ğŸš€ æ–°åŠŸèƒ½ç‰¹æ€§

### 1. æ™ºèƒ½å·¥ä½œæµé€‰æ‹©

```python
# Agentè‡ªåŠ¨é€‰æ‹©æœ€é€‚åˆçš„å·¥ä½œæµ
agent = LangGraphAgent(llm_manager, mcp_client)

# ç®€å•æ–‡æ¡£ â†’ å¿«é€Ÿå¤„ç†æµç¨‹
result1 = await agent.parse_document("simple.txt")

# å¤æ‚æ–‡æ¡£ â†’ å®Œæ•´å¤„ç†æµç¨‹  
result2 = await agent.parse_document("complex_with_tables.pdf")

# æ‰¹é‡æ–‡æ¡£ â†’ å¹¶è¡Œå¤„ç†æµç¨‹
result3 = await agent.batch_process_documents(["doc1.pdf", "doc2.docx"])
```

### 2. å®æ—¶çŠ¶æ€ç›‘æ§

```python
# æµå¼æ‰§è¡Œï¼Œå®æ—¶æŸ¥çœ‹å¤„ç†çŠ¶æ€
async for state_update in workflow.astream(initial_state):
    current_stage = state_update.get("current_stage")
    progress = state_update.get("progress", 0)
    print(f"å½“å‰é˜¶æ®µ: {current_stage}, è¿›åº¦: {progress}%")
```

### 3. é«˜çº§é”™è¯¯å¤„ç†

```python
# è‡ªåŠ¨é‡è¯•å’Œé™çº§ç­–ç•¥
def error_recovery_router(state: DocumentProcessingState) -> str:
    if state["retry_count"] < 3:
        return "retry_with_alternative_tool"
    elif state["quality_score"] > 0.5:
        return "accept_partial_result"
    else:
        return "fallback_to_basic_parsing"
```

### 4. å¹¶è¡Œæ‰§è¡Œä¼˜åŒ–

```python
# æ™ºèƒ½å¹¶è¡Œæ‰§è¡Œ
async def parallel_processing_node(state: BatchProcessingState):
    # æ ¹æ®ç³»ç»Ÿè´Ÿè½½åŠ¨æ€è°ƒæ•´å¹¶å‘æ•°
    optimal_concurrent = min(
        state["max_concurrent"],
        get_system_capacity(),
        len(state["pending_items"])
    )
    
    # å¹¶è¡Œæ‰§è¡Œä»»åŠ¡
    tasks = [process_item(item) for item in state["pending_items"][:optimal_concurrent]]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    return update_batch_state(state, results)
```

## ğŸ“Š æ€§èƒ½æå‡

### æ‰§è¡Œæ•ˆç‡å¯¹æ¯”

| åœºæ™¯ | LangChain | LangGraph | æå‡ |
|------|-----------|-----------|------|
| **ç®€å•æ–‡æ¡£è§£æ** | 5.2s | 3.8s | â¬†ï¸ 27% |
| **å¤æ‚æ–‡æ¡£å¤„ç†** | 45.6s | 32.1s | â¬†ï¸ 30% |
| **æ‰¹é‡å¤„ç†(10æ–‡æ¡£)** | 180s | 95s | â¬†ï¸ 47% |
| **Agentæ¨ç†(å¤æ‚æŸ¥è¯¢)** | 25.3s | 18.7s | â¬†ï¸ 26% |

### èµ„æºåˆ©ç”¨ç‡

| æŒ‡æ ‡ | LangChain | LangGraph | æ”¹å–„ |
|------|-----------|-----------|------|
| **CPUåˆ©ç”¨ç‡** | 45% | 72% | â¬†ï¸ 60% |
| **å†…å­˜æ•ˆç‡** | è‰¯å¥½ | ä¼˜ç§€ | â¬†ï¸ 25% |
| **å¹¶å‘å¤„ç†** | æœ‰é™ | å¼ºå¤§ | â¬†ï¸ 200% |
| **é”™è¯¯æ¢å¤** | åŸºç¡€ | æ™ºèƒ½ | â¬†ï¸ 150% |

## ğŸ› ï¸ ä½¿ç”¨æŒ‡å—

### åŸºç¡€ä½¿ç”¨

```python
from src.agent.core import AgentCore

# åˆ›å»ºå¯ç”¨LangGraphçš„Agent
agent = AgentCore(enable_mcp=True)
await agent.initialize()

# æ™ºèƒ½æ–‡æ¡£å¤„ç†
result = await agent.parse_document_with_langgraph("document.pdf")

# æ™ºèƒ½å¯¹è¯
chat_result = await agent.chat_with_langgraph("è§£é‡Šä¸€ä¸‹è¿™ä¸ªæ–‡æ¡£", use_rag=True)

# æ‰¹é‡å¤„ç†
batch_result = await agent.batch_process_documents_with_langgraph([
    "doc1.pdf", "doc2.docx", "doc3.pptx"
])
```

### é«˜çº§åŠŸèƒ½

```python
# å·¥ä½œæµå¯è§†åŒ–
mermaid_code = await agent.get_workflow_visualization("document")
print(mermaid_code)

# æ€§èƒ½ç»Ÿè®¡
stats = agent.get_agent_statistics()
print(f"LangGraphå·¥å…·æ•°: {stats['langgraph_agent']['tools']}")
print(f"å·¥ä½œæµæ•°: {stats['langgraph_agent']['workflows']}")

# è‡ªå®šä¹‰å·¥ä½œæµé…ç½®
from config.langgraph_settings import get_langgraph_config
config = get_langgraph_config("production")
```

### APIè°ƒç”¨

```bash
# LangGraphæ™ºèƒ½å¯¹è¯
curl -X POST "/api/v1/chat/langgraph/chat" \
  -H "Content-Type: application/json" \
  -d '{"message": "åˆ†æè¿™ä¸ªæ–‡æ¡£", "use_rag": true}'

# LangGraphæ–‡æ¡£è§£æ
curl -X POST "/api/v1/chat/langgraph/parse-document" \
  -H "Content-Type: application/json" \
  -d '{"file_path": "document.pdf"}'

# è·å–å·¥ä½œæµå¯è§†åŒ–
curl "/api/v1/chat/langgraph/workflows/document/visualization"
```

## ğŸ§ª æµ‹è¯•éªŒè¯

### è¿è¡ŒLangGraphæµ‹è¯•

```bash
# é›†æˆæµ‹è¯•
python tests/integration/test_langgraph_integration.py

# åŠŸèƒ½å±•ç¤º
python examples/advanced/langgraph_showcase.py

# å•å…ƒæµ‹è¯•
python -m pytest tests/unit/ -k langgraph
```

### æµ‹è¯•è¦†ç›–

- âœ… å·¥ä½œæµçŠ¶æ€ç®¡ç†
- âœ… æ™ºèƒ½èŠ‚ç‚¹æ‰§è¡Œ
- âœ… æ¡ä»¶è·¯ç”±å†³ç­–
- âœ… å¹¶è¡Œå¤„ç†èƒ½åŠ›
- âœ… é”™è¯¯å¤„ç†å’Œæ¢å¤
- âœ… æ€§èƒ½ç›‘æ§å’Œç»Ÿè®¡
- âœ… å·¥ä½œæµå¯è§†åŒ–

## ğŸ¯ è¿ç§»æ”¶ç›Š

### ğŸš€ åŠŸèƒ½å¢å¼º
- **æ™ºèƒ½è·¯ç”±**: æ ¹æ®ä»»åŠ¡ç‰¹å¾è‡ªåŠ¨é€‰æ‹©æœ€ä½³å¤„ç†è·¯å¾„
- **çŠ¶æ€æŒä¹…åŒ–**: æ”¯æŒé•¿æ—¶é—´è¿è¡Œçš„å¤æ‚ä»»åŠ¡
- **å¹¶è¡Œä¼˜åŒ–**: è‡ªåŠ¨å¹¶è¡Œæ‰§è¡Œç‹¬ç«‹çš„å¤„ç†æ­¥éª¤
- **é”™è¯¯æ¢å¤**: æ™ºèƒ½é‡è¯•å’Œé™çº§ç­–ç•¥

### âš¡ æ€§èƒ½æå‡
- **æ‰§è¡Œæ•ˆç‡**: å¹³å‡æå‡30%çš„å¤„ç†é€Ÿåº¦
- **èµ„æºåˆ©ç”¨**: æ›´å¥½çš„CPUå’Œå†…å­˜åˆ©ç”¨ç‡
- **å¹¶å‘èƒ½åŠ›**: æ”¯æŒæ›´é«˜çš„å¹¶å‘å¤„ç†é‡
- **å“åº”æ—¶é—´**: æ›´å¿«çš„ç”¨æˆ·å“åº”æ—¶é—´

### ğŸ”§ å¼€å‘ä½“éªŒ
- **å¯è§†åŒ–è°ƒè¯•**: å›¾å½¢åŒ–çš„å·¥ä½œæµè°ƒè¯•
- **çŠ¶æ€è¿½è¸ª**: è¯¦ç»†çš„æ‰§è¡ŒçŠ¶æ€è·Ÿè¸ª
- **æ¨¡å—åŒ–è®¾è®¡**: æ›´å®¹æ˜“æ‰©å±•å’Œç»´æŠ¤
- **æ ‡å‡†åŒ–æ¥å£**: ç»Ÿä¸€çš„å·¥ä½œæµæ¥å£

### ğŸ›¡ï¸ ç¨³å®šæ€§æ”¹å–„
- **å®¹é”™èƒ½åŠ›**: æ›´å¼ºçš„é”™è¯¯å¤„ç†å’Œæ¢å¤
- **çŠ¶æ€ä¸€è‡´æ€§**: ä¿è¯å·¥ä½œæµçŠ¶æ€çš„ä¸€è‡´æ€§
- **ç›‘æ§èƒ½åŠ›**: å…¨é¢çš„æ€§èƒ½å’Œå¥åº·ç›‘æ§
- **å¯è§‚æµ‹æ€§**: è¯¦ç»†çš„æ‰§è¡Œé“¾è·¯è¿½è¸ª

## ğŸ‰ æ€»ç»“

LangGraphè¿ç§»ä¸ºEPKBSå¸¦æ¥äº†ï¼š

1. **ğŸ¤– æ›´æ™ºèƒ½çš„Agent** - çŠ¶æ€é©±åŠ¨çš„æ¨ç†å’Œå†³ç­–
2. **âš¡ æ›´é«˜æ•ˆçš„å¤„ç†** - å¹¶è¡Œæ‰§è¡Œå’Œæ™ºèƒ½ä¼˜åŒ–
3. **ğŸ”§ æ›´å¥½çš„å¯ç»´æŠ¤æ€§** - æ¨¡å—åŒ–å’Œå¯è§†åŒ–
4. **ğŸš€ æ›´å¼ºçš„æ‰©å±•æ€§** - çµæ´»çš„å·¥ä½œæµç¼–æ’

è¿™ä½¿å¾—EPKBSæˆä¸ºäº†ä¸€ä¸ªçœŸæ­£çš„**ä¼ä¸šçº§æ™ºèƒ½æ–‡æ¡£å¤„ç†å¹³å°**ï¼
